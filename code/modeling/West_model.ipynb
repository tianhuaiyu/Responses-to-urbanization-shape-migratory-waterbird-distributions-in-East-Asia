{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt  \n",
    "import matplotlib.colors as col\n",
    "\n",
    "from pdpbox import pdp\n",
    "from matplotlib import cm\n",
    "from pdpbox import info_plots\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from matplotlib.pyplot import MultipleLocator\n",
    "\n",
    "plt.rc('font',family='Arial')\n",
    "plt.rcParams ['svg.fonttype'] ='none'\n",
    "plt.rcParams ['svg.fonttype'] ='none'\n",
    "pd.options.mode.chained_assignment = None\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train \n",
    "train = pd.read_csv(r'../../data/west/train.csv',index_col=0)\n",
    "train['month'] = train['date'].apply(lambda x:pd.Timestamp(x).month)\n",
    "train = train.drop(columns=['date','lon','lat','Open Water','Urban-Built-up','Snow-Ice'])\n",
    "X_train=train.iloc[:,1:]\n",
    "y_train=train.iloc[:,0]\n",
    "#test \n",
    "test = pd.read_csv(r'../../data/west/test.csv',index_col=0)\n",
    "test['month'] = test['date'].apply(lambda x:pd.Timestamp(x).month)\n",
    "test = test.drop(columns=['date','lon','lat','Open Water','Urban-Built-up','Snow-Ice'])\n",
    "X_test=test.iloc[:,1:]\n",
    "y_test=test.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = XGBClassifier(\n",
    "                  n_jobs=4,\n",
    "                  max_depth=8,\n",
    "                  learning_rate=0.03,\n",
    "                  n_estimators=300,\n",
    "                  verbosity=1,\n",
    "                  objective='binary:logistic',\n",
    "                  booster='gbtree',\n",
    "                  gamma=0.4,\n",
    "                  min_child_weight=4,\n",
    "                  subsample=0.9,\n",
    "                  colsample_bytree=0.8,\n",
    "                  reg_alpha=0.1,\n",
    "                  reg_lambda=1,\n",
    "                  base_score=0.5,\n",
    "                  eval_metric='auc',\n",
    "              )\n",
    "xgb_model.fit(X_train, y_train,eval_set=[(X_test, y_test)],verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### varibale importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_dict = xgb_model.get_booster().get_score(importance_type='weight')\n",
    "model_importance = pd.DataFrame([imp_dict.keys(),imp_dict.values()]).T\n",
    "model_importance.columns=['Variable','Weight']\n",
    "model_importance['Weight'] = model_importance.Weight.apply(lambda x:x/sum(model_importance.Weight))\n",
    "model_importance = model_importance.sort_values(by='Weight',ascending=False)\n",
    "model_importance.to_csv(r'../../result/figure_data/variable_importance/west.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generate partial dependence plot by pdpbox\n",
    "#### Calculate 2d partial dependence plot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_features = list(X_train.columns)\n",
    "pdp_month_dL = pdp.pdp_interact(model=xgb_model,\n",
    "                                dataset=train,\n",
    "                                model_features=data_features,\n",
    "                                features=['month', 'distance_light'],\n",
    "                                num_grid_points=[12, 11],\n",
    "                                grid_types = ['equal','percentile'],\n",
    "                                n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00000000e+00, 5.43671652e-02, 2.17739955e+00, 4.66250627e+00,\n",
       "       8.84273668e+00, 1.50846849e+01, 2.40062055e+01, 3.67489868e+01,\n",
       "       5.49981314e+01, 1.00333032e+02, 4.31023533e+02])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdp_month_dL.feature_grids[0]\n",
    "(pdp_month_dL.feature_grids[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_features = list(X_train.columns)\n",
    "pdp_month_dL = pdp.pdp_interact(model=xgb_model,\n",
    "                                dataset=train,\n",
    "                                model_features=data_features,\n",
    "                                features=['month', 'distance_light'],\n",
    "                                num_grid_points=[12, 11],\n",
    "                                grid_types = ['equal','percentile'],\n",
    "                                n_jobs=1)\n",
    "pdp_month_dL = pdp.pdp_interact(model=xgb_model,\n",
    "                                dataset=train,\n",
    "                                model_features=data_features,\n",
    "                                features=['month', 'distance_light'],\n",
    "                                num_grid_points=[12, 11],\n",
    "                                grid_types = ['equal','percentile'],\n",
    "                                ##grid[1].astype(int) will ingnore 0.5,and generate list which length=10, so the grid[1] was inputted manually\n",
    "                                cust_grid_points=[pdp_month_dL.feature_grids[0],[0,0.5,2,5,9,15,24,37,55,100,431]],\n",
    "                                #percentile_ranges=[ None,(0, 95)],\n",
    "                                n_jobs=1)\n",
    "pdp_v = pdp_month_dL.pdp.preds.values\n",
    "pdp_v.resize(12,11)\n",
    "pd_pdp = pd.DataFrame(pdp_v).T\n",
    "pd_pdp.columns = pdp_month_dL.feature_grids[0].astype(int)\n",
    "pd_pdp['Distance to light'] = pdp_month_dL.feature_grids[1]\n",
    "pd_pdp = pd_pdp.set_index('Distance to light')\n",
    "pd_pdp.to_csv(r'../../result/figure_data/2d_pdp/figure_2a_west.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate the figure2a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = r'../../result/figure_data/2d_pdp/figure_2a_west.csv'\n",
    "df = pd.read_csv(file).sort_values(by='Distance to light',ascending=False)\n",
    "df['Distance to light'] = df.apply(lambda x:round(x['Distance to light'],1),axis=1)\n",
    "df = df.T\n",
    "df.columns=df.iloc[0,:]\n",
    "df = df.drop(index='Distance to light')\n",
    "df = df[sorted(df.columns)]\n",
    "grid_kws = {\"width_ratios\": (0.9, 0.06)}  # heatmap:colorbar = 0.9ï¼š0.1\n",
    "\n",
    "fig, (ax, cbar_ax)  = plt.subplots(1, 2,gridspec_kw=grid_kws,figsize=(10,10)) \n",
    "\n",
    "sns.heatmap(data=df,vmin=0.38,vmax=0.62,cmap='RdYlBu_r',linewidths=0.1,robust=False,\n",
    "                square=False,ax=ax,cbar_ax=cbar_ax,cbar_kws={\"orientation\": \"vertical\"})\n",
    "ax.set_xticklabels([0,0.5,2,5,9,15,24,37,55,100,431],fontdict={'size':22})\n",
    "ax.set_yticklabels(['January','February','March','April','May','June','July',\n",
    "                    'August','September','October','November','December'],rotation=0,fontdict={'size':26})\n",
    "\n",
    "ax.set_xlabel(\"Distance to light (km)\",fontdict={'size':26},labelpad=10)\n",
    "cbar_ax.set_yticklabels((cbar_ax.get_yticklabels()),fontdict={'size':22})\n",
    "ax.set_title(\"Western China\",fontdict={'size':32},pad=25)\n",
    "\n",
    "plt.subplots_adjust(left = None,bottom = None,right =None,top = None,wspace = 0.1,hspace = None)\n",
    "plt.savefig(r'../../result/figure/2d_pdp/figure_2a_west.pdf',dpi=300,bbox_inches = 'tight')\n",
    "plt.savefig(r'../../result/figure/2d_pdp/figure_2a_west.png',dpi=300,bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate 1d partial dependence plot for every vaibale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def par_dep(xs, frame, model, resolution=25, bins=[None]):   \n",
    "    pd.options.mode.chained_assignment = None\n",
    "    par_dep_frame = pd.DataFrame(columns=[xs, 'partial_dependence'])\n",
    "    col_cache = frame.loc[:, xs].copy(deep=True)\n",
    "    if bins[0] == None:\n",
    "        min_ = frame[xs].min()\n",
    "        max_ = frame[xs].max()\n",
    "        by = (max_ - min_)/resolution\n",
    "\n",
    "        bins = np.arange(min_, max_, by)\n",
    "        print(bins)\n",
    "    for j in bins:\n",
    "        frame.loc[:, xs] = j\n",
    "        #dframe = xgb.DMatrix(frame)\n",
    "        par_dep_i = pd.DataFrame(model.predict_proba(frame)[:,1])\n",
    "        par_dep_j = par_dep_i.mean()[0]\n",
    "        par_dep_frame = par_dep_frame.append({xs:j,\n",
    "                                              'partial_dependence': par_dep_j}, \n",
    "                                              ignore_index=True)\n",
    "    frame.loc[:, xs] = col_cache\n",
    "    return par_dep_frame\n",
    "        \n",
    "def hist(xs, frame,bins):   \n",
    "    pd.options.mode.chained_assignment = None\n",
    "    hist_list = []\n",
    "    \n",
    "    for i in range(len(bins)-1):\n",
    "        temp = len(frame[xs][(frame[xs]>=bins[i]) & (frame[xs]<bins[i+1])])\n",
    "        hist_list.append([bins[i],temp/len(frame[xs])])\n",
    "        \n",
    "    temp = len(frame[xs][(frame[xs]>=bins[-1])])\n",
    "    hist_list.append([bins[-1],temp/len(frame[xs])])\n",
    "    hist_df = pd.DataFrame(hist_list,columns=[xs,'hist'])\n",
    "    return hist_df\n",
    "\n",
    "## è¾“å‡ºæ‰€æœ‰çš„histå’Œpdpï¼Œè¾“å…¥X_totalå’Œmodel\n",
    "def out_pdp_hist(par_dataset,xgb_model,V_bins,save_path =None,variables=None):\n",
    "    if save_path==None:\n",
    "        save_path=r'../../result/figure_data/1d_pdp/'\n",
    "    if variables==None:\n",
    "        variables=['Barren', 'Cultivated and Managed Vegetation',\n",
    "                    'Deciduous Broadleaf Trees', 'Evergreen Broadleaf Trees',\n",
    "                    'Evergreen Deciduous Needleleaf Trees', 'Herbaceous Vegetation',\n",
    "                    'Mixed-Other Trees', 'Regularly Flooded Vegetation', 'Shrubs',\n",
    "                    'Snow-Ice', 'distance_light', 'distance_water', 'Temperature',\n",
    "                    'U_Wind', 'V_wind', 'Precipitation', 'NDVI','Pop','month','year_precipitation']\n",
    "    #X = par_dataset[variables]\n",
    "    for v in variables:\n",
    "        #print(v)\n",
    "        plot_bin = V_bins[v]\n",
    "        par_dep_v = par_dep(v,par_dataset, xgb_model,bins=plot_bin)\n",
    "        hist_v = hist(v,par_dataset,bins=plot_bin)\n",
    "        if v=='Air_pressure':\n",
    "            v='Surface Pressure'\n",
    "        par_dep_v.to_csv(save_path+'/pdp_csv/%s_%s.csv'%('pdp',v),index=False)\n",
    "        hist_v.to_csv(save_path+'/hist_csv/%s_%s.csv'%('hist',v),index=False) \n",
    "        print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è®¡ç®—ä¸€å¥—V_bins \n",
    "V_bins ={}\n",
    "resolution = 20\n",
    "for i in X_train.columns:\n",
    "    if i=='month':\n",
    "        V_bins[i]=np.arange(1,13,1)\n",
    "    else:\n",
    "        max_ = X_train[i].max()\n",
    "        min_ = X_train[i].min()\n",
    "        by = (max_ - min_)/resolution\n",
    "        V_bins[i] = np.append(np.arange(min_, max_, by),max_)\n",
    "        \n",
    "my_bins = V_bins\n",
    "my_save = r'../../result/figure_data/1d_pdp/west/'\n",
    "my_variables = X_train.columns.to_list()\n",
    "out_pdp_hist(par_dataset=X_train,xgb_model=xgb_model,V_bins=my_bins,save_path=my_save,variables=my_variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate the Extended Data Figure 11-12"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geo",
   "language": "python",
   "name": "geo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
